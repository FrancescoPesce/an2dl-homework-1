{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuwVgG3Vbbka"
   },
   "source": [
    "# Artificial Neural Networks and Deep Learning\n",
    "\n",
    "---\n",
    "\n",
    "## Homework 1\n",
    "\n",
    "The following is a notebook containing the code for the final model we submitted, along with some code used in previous models for reference. It is meant to be run locally, but can be run on Google Colab by uncommenting some lines, if usage limits allow for it. The code takes about 3 hours to run to completion on an old system with an RTX 2060 Mobile, an AMD Ryzen 7 3750H and 16 GB of RAM.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dw_-hFm6bjY6"
   },
   "source": [
    "## üåê Connect Colab to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23716,
     "status": "ok",
     "timestamp": 1731183840005,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "y2S4GWr3Uoa8",
    "outputId": "d4e4e627-5e6f-4a53-cba9-ae12a6116476"
   },
   "outputs": [],
   "source": [
    "# For Colab only.\n",
    "#from google.colab import drive\n",
    "\n",
    "#drive.mount('/gdrive')\n",
    "#%cd /gdrive/My Drive/[2024-2025] AN2DL/Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7IqZP5Iblna"
   },
   "source": [
    "## ‚öôÔ∏è Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix library versions (only on the first installation).\n",
    "# This is needed because the code sometimes breaks if the libraries are\n",
    "# installed outside the VSCode environment. Furthermore, some libraries\n",
    "# need to be downgraded to match the same version as Google Colab and \n",
    "# Codabench, and KerasCV breaks if installed after Keras.\n",
    "#!python3 -m pip uninstall tensorflow -y\n",
    "#!python3 -m pip uninstall keras -y\n",
    "#!python3 -m pip uninstall keras-cv -y\n",
    "#!python3 -m pip install keras-cv\n",
    "#!python3 -m pip install tensorflow==2.17.0\n",
    "#!python3 -m pip install keras==3.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10362,
     "status": "ok",
     "timestamp": 1731183850359,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "CO6_Ft_8T56A"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras as tfk\n",
    "from tensorflow.keras import layers as tfkl\n",
    "\n",
    "import keras_cv.layers\n",
    "\n",
    "# Seed-setting is done as a means to ensure reproducibility. Being able to \n",
    "# reproduce the results is crucial for debugging and verifying the correctness\n",
    "# of the code.\n",
    "seed = 11037\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "import random\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GN_cpHlSboXV"
   },
   "source": [
    "## ‚è≥ Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 882,
     "status": "ok",
     "timestamp": 1731183853802,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "pLaoDaG1V1Yg"
   },
   "outputs": [],
   "source": [
    "# Read training_set.npz to get the dataframe.\n",
    "data = np.load('training_set.npz', allow_pickle=True)\n",
    "\n",
    "# Up to the 11958th image, everything seems to be normal. In intervals from\n",
    "# 11959 to 13558 and from 13559 to 13758, the images have been overlaid with\n",
    "# irrelevant images. These images are not relevant to the classification task\n",
    "# and should be ignored.\n",
    "images = data['images'][:11959]\n",
    "labels = data['labels'][:11959]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19254,
     "status": "ok",
     "timestamp": 1731183873357,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "58ux8jweXc5q",
    "outputId": "3359968f-f8a1-4654-d1f4-ef4997cf353c"
   },
   "outputs": [],
   "source": [
    "# Images are stored as 96x96x3 numpy arrays.\n",
    "print(\"Shape of all images:\")\n",
    "print(images[0].shape)\n",
    "\n",
    "# Count the images.\n",
    "print()\n",
    "print(\"Total number of images: \")\n",
    "total_num_images = images.shape[0]\n",
    "print(total_num_images)\n",
    "\n",
    "# Count the amount of images with a given label. We do this to see if the\n",
    "# dataset is balanced, which it isn't. Some labels contain more images than\n",
    "# others, relative to the total number of images.\n",
    "print()\n",
    "print(\"Number of images with a given label:\")\n",
    "for n, elm in enumerate(np.unique(labels, return_counts=True)[-1]):\n",
    "    print(f\"Label {n}: {elm} ({np.round(elm/total_num_images*100, 1)}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "executionInfo": {
     "elapsed": 25372,
     "status": "ok",
     "timestamp": 1731183898723,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "VXJLnm3MXc5r",
    "outputId": "7f08ab99-63b5-4dc9-b839-eb5b8f2ada5b"
   },
   "outputs": [],
   "source": [
    "# Display the first few images with matplotlib, in order to figure out what\n",
    "# the images look like, and whether or not they contain any irrelevant data.\n",
    "plotted_images = 6\n",
    "fig, axs = plt.subplots(1, plotted_images, figsize=(20, 20))\n",
    "\n",
    "for i in range(plotted_images):\n",
    "    axs[i].imshow(images[i])\n",
    "    axs[i].set_title(f\"Label: {labels[i]}\")\n",
    "    axs[i].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split in train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data in training and validation sets. We use 80% of the data for \n",
    "# training and 20% for validation. The stratify parameter is used to ensure \n",
    "# that the distribution of labels is the same in both sets.\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    images,\n",
    "    labels,\n",
    "    test_size=0.2,\n",
    "    random_state=seed,\n",
    "    stratify=labels\n",
    ")\n",
    "\n",
    "# Print the shapes of the resulting sets. This is done to ensure that the\n",
    "# splitting was correctly applied to the data.\n",
    "print('Overall shape:\\t\\t', images.shape, labels.shape)\n",
    "print('Training set shape:\\t', X_train.shape, y_train.shape)\n",
    "print('Validation set shape:\\t', X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data and encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data to the range [0, 1].\n",
    "X_train = (X_train / 255).astype('float32')\n",
    "X_val = (X_val / 255).astype('float32')\n",
    "\n",
    "# Print the first few pixel values of the first image, to verify that the\n",
    "# normalization was successful. These values correspond to the RGB values of\n",
    "# the first pixel in the first image, and they should range from 0 to 1.\n",
    "print('First image pixel values:')\n",
    "print(X_train[0, 0, 0, :])\n",
    "\n",
    "# Convert labels to categorical format using one-hot encoding.\n",
    "# We need to convert the labels to a categorical format, since the model \n",
    "# will output a probability distribution over the classes.\n",
    "# To do this, we use one-hot encoding.\n",
    "y_train = tfk.utils.to_categorical(y_train)\n",
    "y_val = tfk.utils.to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "executionInfo": {
     "elapsed": 1686,
     "status": "ok",
     "timestamp": 1731183908817,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "kX2zZSDSXc5v",
    "outputId": "084295d2-9553-46d3-b992-ff528499dc1f"
   },
   "outputs": [],
   "source": [
    "# Display a sample of images from the dataset. This sample is randomly selected\n",
    "# from the training set. The images are displayed with their corresponding\n",
    "# labels. Once again, this is done to ensure that the data is correctly\n",
    "# preprocessed. We can't know whether or not the labels are correct, since we\n",
    "# can't differentiate between blood cell types, but we can at least verify that\n",
    "# images with the same label look similar, and get an idea of the type of\n",
    "# images we are working with.\n",
    "set_to_sample = X_train\n",
    "labels_to_sample = y_train\n",
    "num_img = 10\n",
    "random_indices = random.sample(range(len(set_to_sample)), num_img)\n",
    "\n",
    "fig, axes = plt.subplots(1, num_img, figsize=(20, 20))\n",
    "\n",
    "# Iterate through the selected number of images.\n",
    "for i, idx in enumerate(random_indices):\n",
    "    ax = axes[i % num_img]\n",
    "    ax.imshow(np.squeeze(set_to_sample[idx]), vmin=0., vmax=1.)\n",
    "    ax.set_title(str(data['labels'][np.argmax(labels_to_sample[idx])]))\n",
    "    ax.axis('off')\n",
    "\n",
    "# Adjust layout and display the images.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí™ Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "img = X_train[0]\n",
    "\n",
    "# Define a sequential model for image augmentation. This particular model\n",
    "# applies a series of random transformations to the input image, but isn't\n",
    "# used for training. It's only used to visualize the effects of the\n",
    "# transformations, in order to verify that they work as intended.\n",
    "augmentation = tf.keras.Sequential([\n",
    "    # A number of transformations are applied to the image.\n",
    "    tfkl.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    tfkl.RandomTranslation(0.2,0.2),\n",
    "    tfkl.RandomRotation(0.2),\n",
    "    tfkl.RandomZoom(0.2),\n",
    "\n",
    "    # Lastly, we chose to apply some color transformations to the image,\n",
    "    # namely brightness and contrast adjustments.\n",
    "    tfkl.RandomBrightness(0.5, value_range=(0,1)),\n",
    "    tfkl.RandomContrast(0.75),\n",
    "], name='preprocessing')\n",
    "\n",
    "# Set up the figure and grid layout for displaying images.\n",
    "fig = plt.figure(constrained_layout=True, figsize=(12, 3))\n",
    "gs = gridspec.GridSpec(1, 4, figure=fig, width_ratios=[1, 1, 1, 1], wspace=0.1)\n",
    "\n",
    "# Display the original image. This is the image that will be augmented, and\n",
    "# the following images will be the result of the augmentation.\n",
    "ax1 = fig.add_subplot(gs[0])\n",
    "ax1.imshow(np.squeeze(img))\n",
    "ax1.axis('off')\n",
    "\n",
    "# Apply augmentation and display the first augmented image.\n",
    "augmented_img = np.clip(augmentation(img)._numpy().astype('float32'), 0., 1.)\n",
    "ax2 = fig.add_subplot(gs[1])\n",
    "ax2.imshow(np.squeeze(augmented_img))\n",
    "ax2.axis('off')\n",
    "\n",
    "# Apply augmentation again and display the second augmented image.\n",
    "augmented_img = np.clip(augmentation(img)._numpy().astype('float32'), 0., 1.)\n",
    "ax3 = fig.add_subplot(gs[2])\n",
    "ax3.imshow(np.squeeze(augmented_img))\n",
    "ax3.axis('off')\n",
    "\n",
    "# Apply augmentation again and display the third augmented image.\n",
    "augmented_img = np.clip(augmentation(img)._numpy().astype('float32'), 0., 1.)\n",
    "ax4 = fig.add_subplot(gs[3])\n",
    "ax4.imshow(np.squeeze(augmented_img))\n",
    "ax4.axis('off')\n",
    "\n",
    "# Show the figure with all images.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to apply overlays (convex combination of the images).\n",
    "# Overlays are used to create new images by combining two images in a\n",
    "# weighted manner. The function takes an image, an overlay image, and a\n",
    "# weight, and returns the resulting image. The weight determines how much\n",
    "# of the overlay image will be visible in the final image. The idea behind\n",
    "# this function started by looking through the doctored images in the\n",
    "# training set, and hypothesizing that the test set would contain similar\n",
    "# images. Overlaying is not used during training, but was used in older\n",
    "# models.\n",
    "def overlay(image, overlay_name, alpha):\n",
    "    # Load the images.\n",
    "    image_overlay = tfk.preprocessing.image.load_img(overlay_name)\n",
    "    image_overlay = tfk.preprocessing.image.img_to_array(image_overlay).astype('uint8')\n",
    "    image_original = image\n",
    "\n",
    "    # Add the images' weighted pixels.\n",
    "    image_result = alpha*image_overlay + (1-alpha)*image_original\n",
    "    image_result = image_result.astype('uint8')\n",
    "\n",
    "    return image_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a random image from the dataset and an overlay.\n",
    "overlay_filename = \"overlay.png\"\n",
    "image_overlay = tfk.preprocessing.image.load_img(overlay_filename)\n",
    "image_overlay = tfk.preprocessing.image.img_to_array(image_overlay).astype('uint8')\n",
    "image_original = images[1]\n",
    "\n",
    "# Display the images.\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 20))\n",
    "\n",
    "axs[0].imshow(image_original)\n",
    "axs[0].set_title(\"Original image\")\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(image_overlay)\n",
    "axs[1].set_title(\"Overlay\")\n",
    "axs[1].axis('off')\n",
    "\n",
    "# Compute the overlay.\n",
    "image_result = overlay(image_original, overlay_filename, 0.6)\n",
    "\n",
    "# Display the result.\n",
    "axs[2].imshow(image_result)\n",
    "axs[2].set_title(\"Result\")\n",
    "axs[2].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a preprocessing pipeline with augmentations.\n",
    "batch_size = 128\n",
    "num_classes = 8\n",
    "augmenter = keras_cv.layers.Augmenter(\n",
    "    [\n",
    "        keras_cv.layers.RandomFlip(seed=seed),\n",
    "        keras_cv.layers.RandAugment(value_range=(0, 1),seed=seed),\n",
    "        keras_cv.layers.CutMix(seed=seed),\n",
    "        #keras_cv.layers.AugMix(value_range=(0, 1),seed=seed),\n",
    "    ],\n",
    ")\n",
    "\n",
    "def preprocess_data(images, labels, augment=False):\n",
    "    inputs = {\"images\": images, \"labels\": labels}\n",
    "    outputs = inputs\n",
    "    if augment:\n",
    "        outputs = augmenter(outputs)\n",
    "    return outputs['images'], outputs['labels']\n",
    "\n",
    "# Augment the training dataset.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.batch(batch_size).map(\n",
    "    lambda x, y: preprocess_data(x, y, augment=True),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE).prefetch(\n",
    "            tf.data.AUTOTUNE)\n",
    "\n",
    "# Augment the validation dataset.\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "val_dataset = val_dataset.batch(batch_size).map(\n",
    "    lambda x, y: preprocess_data(x, y, augment=True),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE).prefetch(\n",
    "            tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yf1-rz1OXc5x"
   },
   "source": [
    "## üßÆ Define Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1731183910020,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "LGCY8oQmXc5y",
    "outputId": "51d93380-0fff-46b9-a792-86777a0b6e69"
   },
   "outputs": [],
   "source": [
    "# Input shape for the model. If everything is set up correctly, the input\n",
    "# shape should be a 96x96x3 tensor, which corresponds to the shape of the\n",
    "# images in the dataset, and the depth of their channels.\n",
    "input_shape = train_dataset.element_spec[0].shape[1:]\n",
    "\n",
    "# Output shape for the model. The output shape should be 8, as there are 8\n",
    "# classes in the dataset. This is the shape of the one-hot encoded labels.\n",
    "output_shape = train_dataset.element_spec[1].shape[1]\n",
    "\n",
    "print(\"Input Shape:\", input_shape)\n",
    "print(\"Output Shape:\", output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1731183910020,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "660E8FDrXc5y",
    "outputId": "9e82025b-97ac-4891-ebf0-c3945feb1346"
   },
   "outputs": [],
   "source": [
    "# Number of training epochs. Note that this number can be relatively high,\n",
    "# as the model uses early stopping to prevent overfitting. The model will\n",
    "# stop training when the validation loss stops decreasing.\n",
    "epochs = 1000\n",
    "\n",
    "# Batch size for training.\n",
    "batch_size = 128\n",
    "\n",
    "# Learning rate: step size for updating the model's weights.\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Print the defined parameters.\n",
    "print(\"Epochs:\", epochs)\n",
    "print(\"Batch Size:\", batch_size)\n",
    "print(\"Learning Rate:\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BcuOtrfwXc5z"
   },
   "source": [
    "## üõ†Ô∏è Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Residual block with configurable parameters (currently unused, but\n",
    "# used in older models). Note that a modified version of this block is used in\n",
    "# the final model, by combining it with the inception block.\n",
    "def residual_block(x, filters, kernel_size=3, padding='same',\n",
    "                   downsample=True, activation='relu', stack=2, name='residual'):\n",
    "\n",
    "    for s in range(stack):\n",
    "        # Save input for skip connection.\n",
    "        skip = x\n",
    "\n",
    "        # First convolutional block with Batch Normalisation and activation.\n",
    "        x = tfkl.Conv2D(filters, kernel_size, padding=padding, name=f'{name}_conv1_{s}')(x)\n",
    "        x = tfkl.BatchNormalization(name=f'{name}_bn1_{s}')(x)\n",
    "        x = tfkl.Activation(activation, name=f'{name}_act1_{s}')(x)\n",
    "\n",
    "        # Second convolutional block.\n",
    "        x = tfkl.Conv2D(filters, kernel_size, padding=padding, name=f'{name}_conv2_{s}')(x)\n",
    "        x = tfkl.BatchNormalization(name=f'{name}_bn2_{s}')(x)\n",
    "\n",
    "        # Adjust skip connection dimension if needed.\n",
    "        if skip.shape[-1] != filters:\n",
    "            skip = tfkl.Conv2D(filters, 1, padding=padding, name=f'{name}_proj_{s}')(skip)\n",
    "            skip = tfkl.BatchNormalization(name=f'{name}_proj_bn_{s}')(skip)\n",
    "\n",
    "        # Add skip connection and apply activation.\n",
    "        x = tfkl.Add(name=f'{name}_add_{s}')([x, skip])\n",
    "        x = tfkl.Activation(activation, name=f'{name}_act2_{s}')(x)\n",
    "\n",
    "    # Optional downsampling.\n",
    "    if downsample:\n",
    "        x = tfkl.MaxPooling2D(2, name=f'{name}_pool')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Inception block with batch normalization (BN) and with multiple\n",
    "# convolution paths and optional downsampling.\n",
    "def inception_block_bn(x, filters, padding='same',\n",
    "                       downsample=True, activation='relu', stack=2, name='inception'):\n",
    "    # This inception block consists of a 1x1 convolution path, a 3x3 convolution\n",
    "    # path, a 5x5 convolution path, and a pooling path. The paths are then\n",
    "    # concatenated to form the final block output.\n",
    "    # The reason for using multiple paths is to allow the model to learn\n",
    "    # different features at different scales, and to increase the model's\n",
    "    # capacity without increasing the number of parameters too much.\n",
    "    # The downsampling (pooling) is not mandatory.\n",
    "\n",
    "    # Loop through specified stack layers for multiple inception paths.\n",
    "    for s in range(stack):\n",
    "        # 1x1 convolution path with batch normalization and activation.\n",
    "        conv1 = tfkl.Conv2D(filters // 4, 1, padding=padding, name=f'{name}_conv1_{s}')(x)\n",
    "        conv1 = tfkl.BatchNormalization(name=f'{name}_bn1_{s}')(conv1)\n",
    "        conv1 = tfkl.Activation(activation, name=f'{name}_act1_{s}')(conv1)\n",
    "\n",
    "        # 3x3 convolution path with initial reduction layer.\n",
    "        conv3_reduce = tfkl.Conv2D(filters // 8, 1, padding=padding, name=f'{name}_conv3_reduce_{s}')(x)\n",
    "        conv3_reduce = tfkl.BatchNormalization(name=f'{name}_bn3_reduce_{s}')(conv3_reduce)\n",
    "        conv3_reduce = tfkl.Activation(activation, name=f'{name}_act3_reduce_{s}')(conv3_reduce)\n",
    "        conv3 = tfkl.Conv2D(filters // 4, 3, padding=padding, name=f'{name}_conv3_{s}')(conv3_reduce)\n",
    "        conv3 = tfkl.BatchNormalization(name=f'{name}_bn3_{s}')(conv3)\n",
    "        conv3 = tfkl.Activation(activation, name=f'{name}_act3_{s}')(conv3)\n",
    "\n",
    "        # 5x5 convolution path with initial reduction layer.\n",
    "        conv5_reduce = tfkl.Conv2D(filters // 12, 1, padding=padding, name=f'{name}_conv5_reduce_{s}')(x)\n",
    "        conv5_reduce = tfkl.BatchNormalization(name=f'{name}_bn5_reduce_{s}')(conv5_reduce)\n",
    "        conv5_reduce = tfkl.Activation(activation, name=f'{name}_act5_reduce_{s}')(conv5_reduce)\n",
    "        conv5 = tfkl.Conv2D(filters // 4, 5, padding=padding, name=f'{name}_conv5_{s}')(conv5_reduce)\n",
    "        conv5 = tfkl.BatchNormalization(name=f'{name}_bn5_{s}')(conv5)\n",
    "        conv5 = tfkl.Activation(activation, name=f'{name}_act5_{s}')(conv5)\n",
    "\n",
    "        # Pooling path with projection for spatial dimensionality reduction.\n",
    "        pool = tfkl.MaxPooling2D(3, strides=1, padding=padding, name=f'{name}_pooling_{s}')(x)\n",
    "        pool_proj = tfkl.Conv2D(filters // 4, 1, padding=padding, name=f'{name}_pool_proj_{s}')(pool)\n",
    "        pool_proj = tfkl.BatchNormalization(name=f'{name}_bn_pool_proj_{s}')(pool_proj)\n",
    "        pool_proj = tfkl.Activation(activation, name=f'{name}_act_pool_proj_{s}')(pool_proj)\n",
    "\n",
    "        # Concatenate all paths to form the final block output.\n",
    "        x = tfkl.Concatenate(name=f'{name}_concat_{s}')([conv1, conv3, conv5, pool_proj])\n",
    "\n",
    "    # Apply downsampling if specified.\n",
    "    if downsample:\n",
    "        x = tfkl.MaxPooling2D(2, name=f'{name}_pool')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the a residual block using an inception block instead of the \n",
    "# convolutional path. This mixed block is used in the final model, and it\n",
    "# combines the benefits of both residual and inception blocks. We believe\n",
    "# that the residual and inception blocks are complementary, as their guesses\n",
    "# don't seem to perfectly overlap. See the report for more details.\n",
    "def inception_residual(x, filters, padding='same', downsample=True, \n",
    "                       activation='relu', stack=2, inception_stack=2,\n",
    "                       name='residual'):\n",
    "\n",
    "    for s in range(stack):\n",
    "        # Save input for skip connection.\n",
    "        skip = x\n",
    "\n",
    "        # Create the inception block.\n",
    "        x = inception_block_bn(x, filters, padding, downsample=False, activation=activation,\n",
    "                               stack=inception_stack, name=f'{name}_inception_{s}')\n",
    "\n",
    "        # Adjust skip connection dimension if needed.\n",
    "        if skip.shape[-1] != filters:\n",
    "            skip = tfkl.Conv2D(filters, 1, padding=padding, name=f'{name}_proj_{s}')(skip)\n",
    "            skip = tfkl.BatchNormalization(name=f'{name}_proj_bn_{s}')(skip)\n",
    "\n",
    "        # Add skip connection and apply activation.\n",
    "        x = tfkl.Add(name=f'{name}_add_{s}')([x, skip])\n",
    "        x = tfkl.Activation(activation, name=f'{name}_act2_{s}')(x)\n",
    "\n",
    "    # Optional downsampling.\n",
    "    if downsample:\n",
    "        x = tfkl.MaxPooling2D(2, name=f'{name}_pool')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 240,
     "status": "ok",
     "timestamp": 1731184864492,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "VqrlpQsIXc50"
   },
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    input_shape=input_shape,        # Input shape for the model.\n",
    "    output_shape=output_shape,      # Output shape for the model.\n",
    "    learning_rate=learning_rate,    # Learning rate for the optimizer.\n",
    "    augmentation=None,              # Optional data augmentation.\n",
    "    seed=seed                       # Random seed for reproducibility.\n",
    "):\n",
    "    # Set the random seed for reproducibility.\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "    # Define the input layer.\n",
    "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
    "\n",
    "    # From here on, we denote the output of each layer as `x`, and we will\n",
    "    # build the model by successively adding layers to it by reassigning it.\n",
    "\n",
    "    # Apply optional data augmentation.\n",
    "    if augmentation == None:\n",
    "        # If no Keras augmentation is specified, we use the input layer as is.\n",
    "        x = input_layer\n",
    "    else:\n",
    "        x = augmentation(input_layer)\n",
    "\n",
    "    # Apply first convolutional layer, activation, and pooling.\n",
    "    x = tfkl.Conv2D(filters=60, kernel_size=3, padding='same', name='conv0')(x)\n",
    "    x = tfkl.BatchNormalization(name='norm0')(x)\n",
    "    x = tfkl.ReLU(name='relu0')(x)\n",
    "    x = tfkl.MaxPooling2D(name='mp0')(x)\n",
    "\n",
    "    # Apply second convolutional layer, activation, and pooling.\n",
    "    x = tfkl.Conv2D(filters=120, kernel_size=3, padding='same', name='conv1')(x)\n",
    "    x = tfkl.BatchNormalization(name='norm1')(x)\n",
    "    x = tfkl.ReLU(name='relu1')(x)\n",
    "    x = tfkl.MaxPooling2D(name='mp1')(x)\n",
    "\n",
    "    # Add two residual blocks.\n",
    "    x = inception_residual(x, filters=240, downsample=True, stack=2, inception_stack=2, name='res1')\n",
    "\n",
    "    # Add two more residual blocks.\n",
    "    x = inception_residual(x, filters=480, downsample=True, stack=2, inception_stack=2, name='res2')\n",
    "\n",
    "    # Apply global average pooling.\n",
    "    x = tfkl.GlobalAveragePooling2D(name='gap')(x)\n",
    "\n",
    "    # Add a dense layer with activation.\n",
    "    x = tfkl.Dense(units=128, name='dense1')(x)\n",
    "    x = tfkl.ReLU(name='relu5')(x)\n",
    "    # Add a dropout layer to prevent overfitting.\n",
    "    x = tfkl.Dropout(rate=0.6, name='dropout')(x)\n",
    "\n",
    "    # Define the output layer with softmax activation for classification.\n",
    "    x = tfkl.Dense(units=output_shape, name='dense2')(x)\n",
    "    output_layer = tfkl.Activation('softmax', name='softmax')(x)\n",
    "\n",
    "    # Create the model.\n",
    "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='CNN')\n",
    "\n",
    "    # Compile the model with categorical crossentropy loss and Adam optimizer.\n",
    "    loss = tfk.losses.CategoricalCrossentropy()\n",
    "    optimizer = tfk.optimizers.Adam(learning_rate)\n",
    "    metrics = ['accuracy']\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "    # Return the compiled model.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2171,
     "status": "ok",
     "timestamp": 1731184973630,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "6jxjWSTPiVhg",
    "outputId": "b737bf93-6a53-42ce-e488-3b505770a1ac"
   },
   "outputs": [],
   "source": [
    "# Build the model with specified input and output shapes.\n",
    "# No standard Keras augmentation is used, while Keras CV is used.\n",
    "model = build_model(augmentation=None)\n",
    "\n",
    "# Display a summary of the model architecture.\n",
    "model.summary(expand_nested=True, show_trainable=True)\n",
    "\n",
    "# Plot the model architecture.\n",
    "tfk.utils.plot_model(model, expand_nested=True, show_trainable=True, show_shapes=True, dpi=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSliIxBvbs2Q"
   },
   "source": [
    "## üõ†Ô∏è Train and Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1731185024802,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "O9ZerUc8Xc52"
   },
   "outputs": [],
   "source": [
    "# Define the patience value for early stopping.\n",
    "patience = 40\n",
    "\n",
    "# Create an EarlyStopping callback. This callback is used to stop the training\n",
    "# process when the model's performance on the validation set decreases.\n",
    "early_stopping = tfk.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    patience=patience,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Add a callback to reduce the learning rate after patience/2 epochs of no\n",
    "# increase in validation loss.\n",
    "reduce_lr = tfk.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.2,\n",
    "    patience=patience//2\n",
    ")\n",
    "\n",
    "# Add a callback to store the model at each epoch. This is done in case of crashes\n",
    "# and GPU usage limits on Colab.\n",
    "checkpoint = tfk.callbacks.ModelCheckpoint(\n",
    "    '{epoch:02d}-{val_loss:.2f}.keras', \n",
    "    save_freq=\"epoch\"\n",
    ") \n",
    "\n",
    "# Store the callback in a list, that we will feed to the model.fit function.\n",
    "callbacks = [early_stopping, reduce_lr, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 565664,
     "status": "ok",
     "timestamp": 1731176795036,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "IlfMD2bwXc52",
    "outputId": "68e96674-ff0e-4c24-aa4c-d73ac30c9e82"
   },
   "outputs": [],
   "source": [
    "# Train the model with early stopping callback. Please note that this cell\n",
    "# can take a long time to run, depending on your hardware. The model will\n",
    "# stop training when the validation loss stops decreasing for enough epochs.\n",
    "history = model.fit(\n",
    "    train_dataset,                  # Training data.\n",
    "    batch_size=batch_size,          # Batch size.\n",
    "    epochs=epochs,                  # Number of epochs.\n",
    "    validation_data=val_dataset,    # Validation\n",
    "    callbacks=callbacks             # Early stopping.\n",
    ").history\n",
    "\n",
    "# Calculate and print the final validation accuracy.\n",
    "final_val_accuracy = round(max(history['val_accuracy'])* 100, 2)\n",
    "print(f'Final validation accuracy: {final_val_accuracy}%')\n",
    "\n",
    "# Save the trained model to a file with the accuracy included in the filename.\n",
    "model_filename = 'weights.keras'\n",
    "model.save(model_filename)\n",
    "\n",
    "# Delete the model to free up resources.\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "executionInfo": {
     "elapsed": 1244,
     "status": "ok",
     "timestamp": 1731176850308,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "ox9jqYyyUJo0",
    "outputId": "7fc82126-1864-4da2-9efd-40e62cc2fdfb"
   },
   "outputs": [],
   "source": [
    "# Plot training and validation loss.\n",
    "plt.figure(figsize=(15, 2))\n",
    "plt.plot(history['loss'], label='Training loss', alpha=.8)\n",
    "plt.plot(history['val_loss'], label='Validation loss', alpha=.8)\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.grid(alpha=.3)\n",
    "\n",
    "# Plot training and validation accuracy.\n",
    "plt.figure(figsize=(15, 2))\n",
    "plt.plot(history['accuracy'], label='Training accuracy', alpha=.8)\n",
    "plt.plot(history['val_accuracy'], label='Validation accuracy', alpha=.8)\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(alpha=.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNp6pUZuddqC"
   },
   "source": [
    "## üìä Prepare the Submission\n",
    "\n",
    "The submission is a `.zip` file that includes all the necessary code to run the model. It **must** include a `model.py` file with the following class:\n",
    "\n",
    "```python\n",
    "# file: model.py\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the internal state of the model.\"\"\"\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return a numpy array with the labels corresponding to the input X.\"\"\"\n",
    "```\n",
    "\n",
    "The next cell creates the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 370,
     "status": "ok",
     "timestamp": 1731176863578,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "RKT4h-9xYwiT",
    "outputId": "7a126497-3510-4325-cd41-ae2cc9e7fc04"
   },
   "outputs": [],
   "source": [
    "%%writefile model.py\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tfk\n",
    "from tensorflow.keras import layers as tfkl\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        # Load the CNN.\n",
    "        self.neural_network = tfk.models.load_model('weights.keras')\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Map X to [0,1].\n",
    "        X_normalized = (X / 255).astype('float32')\n",
    "\n",
    "        # Predict.\n",
    "        preds = self.neural_network.predict(X_normalized)\n",
    "        if len(preds.shape) == 2:\n",
    "            preds = np.argmax(preds, axis=1)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 589,
     "status": "ok",
     "timestamp": 1731176866398,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "s18kX1uDconq",
    "outputId": "8c458d79-7665-4c2a-8e0f-b2dd2901d845"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "filename = f'submission_{datetime.now().strftime(\"%y%m%d_%H%M%S\")}.zip'\n",
    "\n",
    "# Create the submission.\n",
    "!zip {filename} model.py weights.keras\n",
    "\n",
    "# Download the submission (Colab only).\n",
    "#from google.colab import files\n",
    "#files.download(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2dQ5qTUtc6e"
   },
   "source": [
    "## üïπÔ∏è Test the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is used to check if the model is working. However, it does not give any information on the model's accuracy on Codabench, which uses a completely different dataset. The final accuracy on Codabench was 0.88 in both phases. The accuracy on the training set is lower than on the validation set due to the Dropout layer, and the accuracy on the validation set is lower than the one on Codabench due to the very aggressive augmentation used in training and valitation. Clearly, the accuracy on the validation set with no augmentation is much higher than the one on Codabench. No local test set is used due to results being almost uncorrelated to the accuracy on Codabench."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12864,
     "status": "ok",
     "timestamp": 1731176945353,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "qHFbbq-N1M0Z"
   },
   "outputs": [],
   "source": [
    "# Import the Model class to test if everything works.\n",
    "import importlib\n",
    "import model\n",
    "importlib.reload(model)\n",
    "model_object = model.Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "executionInfo": {
     "elapsed": 6162,
     "status": "ok",
     "timestamp": 1731177012575,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "YcCnmSTBty-_",
    "outputId": "6bdab44e-e267-4d60-ca42-75ef93636d47"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Predict class probabilities and get predicted classes on the validation set.\n",
    "test_predictions = model_object.predict(X_val * 255)\n",
    "\n",
    "# Extract ground truth classes.\n",
    "test_gt = np.argmax(y_val, axis=1)\n",
    "\n",
    "# Calculate and display test set accuracy.\n",
    "test_accuracy = accuracy_score(test_gt, test_predictions)\n",
    "print(f'Accuracy score over the test set: {round(test_accuracy, 4)}')\n",
    "\n",
    "# Calculate and display test set precision.\n",
    "test_precision = precision_score(test_gt, test_predictions, average='weighted')\n",
    "print(f'Precision score over the test set: {round(test_precision, 4)}')\n",
    "\n",
    "# Calculate and display test set recall.\n",
    "test_recall = recall_score(test_gt, test_predictions, average='weighted')\n",
    "print(f'Recall score over the test set: {round(test_recall, 4)}')\n",
    "\n",
    "# Calculate and display test set F1 score.\n",
    "test_f1 = f1_score(test_gt, test_predictions, average='weighted')\n",
    "print(f'F1 score over the test set: {round(test_f1, 4)}')\n",
    "\n",
    "# Compute the confusion matrix.\n",
    "cm = confusion_matrix(test_gt, test_predictions)\n",
    "\n",
    "# Create labels combining confusion matrix values.\n",
    "labels = np.array([f\"{num}\" for num in cm.flatten()]).reshape(cm.shape)\n",
    "\n",
    "# Plot the confusion matrix with class labels.\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=labels, fmt='', xticklabels=range(8), yticklabels=range(8), cmap='Blues')\n",
    "plt.xlabel('True labels')\n",
    "plt.ylabel('Predicted labels')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "an2dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
