\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{float}
\usepackage{lipsum}
\usepackage{multicol}
\usepackage{xcolor}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{hyperref}
\newcolumntype{Y}{>{\centering\arraybackslash}X}
\usepackage[left=2.00cm, right=2.00cm, top=2.00cm, bottom=2.00cm]{geometry}

\title{AN2DL Reports Template}

\begin{document}

\begin{figure}[H]
      \raggedright
      \includegraphics[scale=0.4]{polimi.png} \hfill
      \includegraphics[scale=0.3]{airlab.jpeg}
\end{figure}

\vspace{5mm}

\begin{center}
      % Select between First and Second
      {\Large \textbf{AN2DL - First Homework Report}}\\
      \vspace{2mm}
      % Change with your Team Name
      {\Large \textbf{LosPollosHermanos}}\\
      \vspace{2mm}
      % Team Members Information
      {\large Mohammadhossein Allahakbari,}
      {\large Michele Miotti,}
      {\large Francesco Pesce}\\
      \vspace{2mm}
      % Codabench Nicknames
      {mh2033,}
      {michelem,}
      {francescopesce}\\
      \vspace{2mm}
      % Matriculation Numbers
      {246639,}
      {249499,}
      {247974}\\
      \vspace{5mm}
      \today
\end{center}
\vspace{5mm}

\begin{multicols}{2}
      % Note: The following sections represent a suggested
      % structure. We don't need to follow it strictly.

      % -----------------------------------------------------------------------
      % INTRODUCTION
      % -----------------------------------------------------------------------
      \section{Introduction}
      % In this section, you should present your project's context and
      % objectives. You might want to:
      % \begin{itemize}
      %     \item Dehe problem (\textit{you may use italics to highlight
      %               definitions})
      %     \item State your goals (\textbf{emphasise key points with bold})
      %     \item Outline your approach
      % \end{itemize}

      % \noindent For instance, you might write: ``This project focuses on
      % \textit{image classification} using \textbf{deep learning} techniques."

      This report presents the results of the \textit{image classification}
      task proposed in the first homework of the Artificial Neural Networks and
      Deep Learning course at Politecnico di Milano. The goal of the project is
      to classify blood cell images into 8 different classes by using deep
      learning techniques such as Convolutional Neural Networks (CNNs).

      % -----------------------------------------------------------------------
      % PROBLEM ANALYSIS
      % -----------------------------------------------------------------------
      \section{Problem Analysis}
      % Here you can discuss your initial analysis of the problem. Consider
      % including:
      % \begin{enumerate}
      %     % 8 classes, 96x96 rgb images, labels, etc
      %     \item Dataset characteristics
      %     \item Main challenges % The test set is horrible
      %     That the test set was not horrible? Is this what they mean?
      %     \item Initial assumptions 
      % \end{enumerate}

      % \noindent If you need to reference papers, use the citation command:
      % Recent work~\cite{lecun2015deep} suggests..."

      The dataset consists around 10,000 RGB images of blood cells, each
      of size 96\(\times\)96 pixels, to be classified into 8 different
      categories. After manually analyzing the dataset, we found that
      a part of it contained duplicate and misleading images that were doctored
      by adding unrelated overlays. We considered this a hint that the test set
      might contain similar images, enabling us to experiment with different
      techniques to improve the model's performance.

      Furthermore, after testing our first model on a local test set, using images
      taken from the dataset we were provided, we found that the model's 
      performance on the Codabench platform was significantly lower. This mismatch
      appearing with multiple models meant that the test set provided on Codabench
      could not be reasonably assumed to have been generated by the same distribution
      that generated the images of the dataset we were provided, and was likely
      doctored in some way.

      The classes within the dataset were imbalanced, with some classes having
      more samples than others, with the highest inbalance being a 2.75x imbalance,
      after removing doctored images. Multiple experiments,such as using data 
      augmentation techniques to balance out the number of samples for each class 
      in the training set, seemed to indicate that the distribution of labels of 
      the traning and test set was similar, so we decided not to adjust the prior 
      distribution of the labels, as that appeared to give worse results in our tests.

      % -----------------------------------------------------------------------   
      % METHOD
      % -----------------------------------------------------------------------
      \section{Method}
      % Not sure what they are asking here. The final model?
      % This section should detail your approach. You can use equations to
      % explain your methodology. For example, a simple model representation:
      % \begin{equation}
      %     \label{eq:model}
      %     f(x) = \text{softmax}(Wx + b)
      % \end{equation}

      % \noindent Or a more complex loss function:
      % \begin{equation}
      %     \label{eq:loss}
      %     \mathcal{L} = -\frac{1}{N}\sum_{i=1}^{N} y_i\log(\hat{y}_i)
      % \end{equation}

      % \noindent Reference these equations in your text, like:``As shown in
      % equation~\ref{eq:model}..."

      Most of the development process used a Jupyter notebook, which was used to load and
      analyse the data, apply augmentation techniques, define and train the models, and
      generate and test the submissions for the Codabench platform.

      We used the whole dataset we were provided, except for the images we believed to be
      doctored, which we discarded. We initially divided our dataset into training, validation
      and test sets, but upon noticing that the accuracy on the test set was unrelated to the
      actual accuracy on Codabench, we decided to get rid of it, and split the dataset into a 
      training set (80\% of the data) and a validation set.

      All of the models we produced are formed of a convolutional CNN, used for feature extraction 
      from the images, and a dense neural network at the top of the net. Since this is a multi-class
      classification problem, the loss function we employed was categorical crossentropy.

      After experimenting with different models and techniques, as detailed in
      the Section \ref{sec:experiments}, we found that the best approach was to 
      use a chain of convolutional and downsampling layers, followed by two instances
      of a custom block that combines the features of residual networks and inception 
      blocks, as illustrated in Section \ref{sec:custom_block}.

      The output of these custom blocks is then fed into a global average
      pooling layer, in order to reduce the dimensionality of the output and as a regularization technique. 
      Finally, a hidden dense layer with 128 units, a Dropout layer for regularization, and an output layer 
      with 8 units and a softmax activation function are used to classify the images.

      The final network has around 1.9 million parameters, and achieved an accuracy of 0.88 on Codabench
      during the development phase. The information provided above describes a family of models, with
      each model differing in the optimizer employed (e.g. Adam or Lion), the number of output channels
      for each layer and the number of convolutional layers before the custom blocks. The final model 
      was developed after analyzing the complex design space spanned by said parameters.

      % -----------------------------------------------------------------------
      % EXPERIMENTS
      % -----------------------------------------------------------------------
      \label{sec:experiments}
      \section{Experiments}
      % Step 1: bad CNN just to test things out
      % Step 2: normal augmentation
      % Step 3: overlaying
      % Step 4: keras cv (gigachad picture)
      % Step 5: testing residual networks (up to 0.8)
      %   and inception blocks (up to 0.72)
      % Step 6: custom block (in detail)
      % Step 7: add more filters
      % Step 8.....: not done yet
      % If you need accuracies, number of parameters etc ask me

      % Failed experiments:
      % transfer learning (bad accuracy) (VGG, MobileNet, ResNet), both with and
      % without fine tuning
      % Lion, stochastic gradient descent with momentum

      % Ideas that worked momentarily:
      % voting mechanism with multiple neural networks
      % averaging weights below a certain validation loss
      \subsection{Successful experiments}

      A number of experiments aimed at increasing the accuracy on the Codabench test
      set were conducted. Some of the experiments were successful, while others were not. 
      The following is a list of experiments, in chronological order, that significantly
      improved the accuracy of the model. For each experiment, multiple models were tested,
      and the best accuracy obtained using each technique is discussed in Section 
      \ref{sec:results}.

      \begin{itemize}
            \item \textbf{Simple CNN:} A simple CNN from one of the laboratory lectures
                  of the course was implemented to test the workflow and the platform.
                  The model performed well on our local training, validation and test 
                  sets, but very badly on the Codabench platform. This simple experiment 
                  immediately made us consider the fact that the test set on Codabench 
                  was likely generated with a different distribution from the dataset 
                  we were provided.
            \item \textbf{Data Augmentation:} We augmented the dataset by
                  following the basic data augmentation techniques taught in class and
                  shown in the laboratory lectures, but only achieved a very slight
                  accuracy improvement.
            \item \textbf{Overlaying:} After finding the doctored images in the
                  dataset, we hypothesized that the test set may contain images
                  doctored in the same way. Therefore, we experimented with applying
                  overlays to the images of the training and validation sets, using
                  different image overlaying techniques, such as multiplying the 
                  normalized pixel values and using convex combinations.
            \item \textbf{Keras CV:} Using the Keras CV library provided the first
                  satisfactory results. Compared to previous data augmentation techniques,
                  the library provided richer augmentations, which could be applied
                  in a complex pipeline. We also attempted to manually implement
                  some of the augmentations, due to some version incompatibilities
                  between Keras CV, Keras and Tensorflow. The manual implementations 
                  performed worse because they lacked an important feature of Keras CV
                  augmentations: augmentation are applied to the images during training, 
                  instead of pre-processing the entire dataset in the beginning, as we
                  did with manual augmentations. While this increases training time,
                  it allows to use different seeds at each iteration, allowing the model
                  to fully learn the information of the training set, as opposed to
                  preprocessing the images, which causes loss of information.
            \item \textbf{Richer architectures:} While previous networks all used trivial 
                  CNN architectures, we tried experimenting with more complex CNNs,
                  with significant result being obtained by using Inception blocks,
                  Residual networks, Global Average Pooling and Batch Normalization layers.
            \item \textbf{Custom Block:} A custom block was implemented to mix the 
                  features of the residual and inception blocks. The rationale and more
                  details are discussed in section \ref{sec:custom_block}. This block 
                  is at the core of the final model we implemented.
      \end{itemize}

      \subsection{Other experiments}

      A failed experiment that merits explicit mention is using transfer learning.
      We tried transfer learning from some well-known CNN architectures, available
      as Keras applications, such as VGG19, ResNet50V2 and MobileNetV2. For all
      architectures, we used the "ImageNet" pre-trained weights, removed the dense
      network and added a custom one. We attempted both training just the dense
      network, freezing the weights of the feature extraction network, and unfreezing
      top convolutional layers, but achieved very poor results with both techniques.
      Moreover, many pre-trained networks were large, causing issues with the amount
      of available memory and the limited storage space and performance issues of the
      Codabench platform. Ultimately, for the aforementioned reasons, we decided to 
      avoid transfer learning, with the added result of being able to experiment in
      creating our own custom CNN from scratch.

      Another failed experiment is using the Lion and stochastic gradient descent
      with momentum optimized provided by Keras. We attempted to use these optimizers
      at multiple points of our development, including for the final model. However,
      the results were always sub-par, or at most the same, compared to the Adam 
      optimizer.

      Other failed experiments include performing test-time agumentation, i.e. 
      performing multiple predictions per image, and returning the most common prediction 
      and an attempt to filter out noise in the test set using Fourier transforms (in case
      the test set was doctored by adding noise, which appears to not have been the case).

      Other ideas were successful at first, such as averaging weights from all epochs 
      below a certain validation loss, as a normalization technique, and a voting mechanism 
      with multiple neural networks, acting as a sort of ensemble method. The first idea
      stopped having an effect after the models reached a certain accuracy, and the second
      one was scrapped for two reasons: it only provided very marginal improvements, 
      making computational requirements much larger, and its unorthodox nature: as the 
      project was a mean to learn from the course, we decided to approach the problem by 
      following the methods taught in class.

      % For your experiments, you might want to present your results in tables.
      % Here's an example of a wide table comparing different models:

      % \begin{table*}[t]
      %     \centering
      %     \setlength{\tabcolsep}{3pt}
      %     \caption{An example of wide table. Best results are highlighted in
      %         \textbf{bold}.}
      %     \begin{tabularx}{\textwidth}{lYYYc}
      %         \toprule
      %         Model            & Accuracy                  & Precision
      %                          & Recall                    & ROC AUC
      %         \\
      %         \midrule
      %         VGG18            & 72.20 $\pm$ 3.06          & 94.95 $\pm$ 0.52
      %                          &
      %         86.95 $\pm$ 0.55 & 80.16 $\pm$ 0.81
      %         \\
      %         Custom Model     & 27.71 $\pm$ 3.19          & 75.70 $\pm$ 1.07
      %                          & 55.75 $\pm$ 2.16          & 36.60 $\pm$ 1.26
      %         \\
      %         ResNet18         & \textbf{89.24 $\pm$ 2.38} & \textbf{95.54
      %         $\pm$ 0.49}      & \textbf{93.43 $\pm$ 1.30} & \textbf{91.68 $\pm$
      %             0.71}
      %         \\
      %         \bottomrule
      %     \end{tabularx}
      %     \label{tab:Performance}
      % \end{table*}

      % \noindent For more specific measurements, you might use a narrower
      % table:

      % \begin{table}[H]
      %     \centering
      %     \setlength{\tabcolsep}{3pt}
      %     \caption{An example of table. Best results may be highlighted in
      %         \textbf{bold}.}
      %     \begin{tabularx}{\linewidth}{lY}
      %         \toprule
      %         Time [$\mu$s] & Distance [mm] \\
      %         \midrule
      %         22$\pm$4      & 8$\pm$1       \\
      %         17$\pm$3      & 7$\pm$1       \\
      %         15$\pm$3      & 6$\pm$1       \\
      %         13$\pm$2      & 5$\pm$1       \\
      %         10$\pm$2      & 4$\pm$1       \\
      %         8$\pm$2       & 3$\pm$1       \\
      %         5$\pm$1       & 2$\pm$1       \\
      %         37$\pm$1      & 1$\pm$1       \\
      %         \bottomrule
      %     \end{tabularx}
      %     \label{tb:Measurements}
      % \end{table}

      % \noindent You can also include figures to visualise your results:
      % \begin{figure}[H]
      %     \centering
      %     \includegraphics[width=0.75\linewidth]{random.jpeg}
      %     \caption{Example figure showing [describe what the figure shows]}
      %     \label{fig:results}
      % \end{figure}

      % \noindent Reference figures using like:``As shown in
      % Figure~\ref{fig:results}..."

      % -----------------------------------------------------------------------
      % CUSTOM BLOCK
      % -----------------------------------------------------------------------
      \label{sec:custom_block}
      \section{Custom Block}
      % Explain the custom block in detail

      Two of the most successful experiments were adding inception blocks and
      residual blocks. In particular, the latter achieved a larger accuracy
      both during training and testing, due to the fact that the training process
      is often not capable of properly train deep models. The residual blocks 
      inject skip connections into the network, which helping the learning process
      by making deeper levers learn residuals with respect to the identity function,
      simplifying the learning process.

      With inception blocks, a set of differently sized filters are applied to the block's 
      input, and the results are concatenated as output channels. This helps the network 
      capture both fine-grained and coarse-grained features of the dataset. The network
      with inception blocks performed worse than the one with residual blocks, likely
      due to the same problem that afflicts deep networks.

      As opposed to previous experiments that seemed to guess correctly or
      incorrectly in a similarly distributed fashion with respect to each
      other, making each network strict upgrade or downgrade from its predecessors, 
      networks containing just residual blocks and just inception blocks were able to correctly
      classify different images. This led us to hypothesize that they captured distinct 
      features of the dataset, and could be combined to improve the accuracy even further.

      A custom block was therefore implemented by combining the residual and
      inception blocks. The block is formed by constructing a residual block's model and
      substituting each convolutional layers and activation with an inception block.

      TODO: add an image here

      % -----------------------------------------------------------------------
      % RESULTS
      % -----------------------------------------------------------------------
      \label{sec:results}
      \section{Results}
      % Keras CV is good
      % Combining residual and inception is good
      % Present your main findings here. You might want to:
      % \begin{itemize}
      %     \item Compare your results with baselines
      %     \item Highlight key achievements using \textbf{bold text}
      %     \item Explain any unexpected outcomes
      % \end{itemize}

      \label{tab:results}
      \begin{table}[H]
          \centering
          \setlength{\tabcolsep}{3pt}
          \caption{Scores obtained by the best model we developed for each technique.
                   Results marked with * are approximate, due to being computed before
                   the submissions reset to the Codabench platform.}
          \begin{tabularx}{\linewidth}{lY}
              \toprule
              Experiment & Score \\
              \midrule
              Simple CNN & 0.20* \\
              Data Augmentation & 0.25* \\
              Overlaying & 0.53 \\
              Keras CV & 0.71 \\
              Richer architectures & 0.80 \\
              Custom Block & 0.88 \\
              \bottomrule
          \end{tabularx}
          \label{tb:Measurements}
      \end{table}

      % -----------------------------------------------------------------------
      % DISCUSSION
      % -----------------------------------------------------------------------
      \section{Discussion}
      % Wait until we have the final results
      % In this section, analyse your results critically. Consider:
      % \begin{itemize}
      %     \item Strengths and weaknesses
      %     \item Limitations and assumptions
      % \end{itemize}

      TODO: write this after final results

      % -----------------------------------------------------------------------
      % CONTRIBUTIONS
      % -----------------------------------------------------------------------
      \section{Contributions}

      Most ideas and propositions were evenly distributed among the team
      members, while actual coding was more specific to each member's
      strengths. Many different branches were created in the repository to
      experiment with different ideas and techniques. The final model was a
      result of combining the best experiments from each branch.

      % -----------------------------------------------------------------------
      % CONCLUSIONS
      % -----------------------------------------------------------------------
      \section{Conclusions}
      % Summarise your work and discuss potential future directions. This is
      % where you can:
      % \begin{itemize}
      %     \item Restate main contributions
      %     \item Suggest improvements
      %     \item Propose future work
      % \end{itemize}

      Overall, the project's challenge-like nature has helped us follow a
      structured approach to solving the problem. Not expecting a pristine test
      set, we were able to experiment with most of the techniques we learned in
      class, instad of immediately finding the best solution.

      % Remember to include the bibliography!
      \bibliography{references}
      \bibliographystyle{abbrv}

\end{multicols}
\end{document}